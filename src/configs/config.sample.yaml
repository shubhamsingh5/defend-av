model: dqn
scenario: 'austria.yml'

# DQN
learning_rate: 0.001
buffer_size: 100000
batch_size: 64
gamma: 0.99
hidden_size: 256
episodes: 1000
train_freq: 100
min_samples: 1000
epsilon_start: 1.0
epsilon_end: 0.001
epsilon_decay: 0.999
target_update_freq: 10

# PPO parameters
use_lstm: true  # or false for regular PPO
learning_rate: 3e-4
n_steps: 256  # or 2048 for non-LSTM
batch_size: 32  # or 64 for non-LSTM
n_epochs: 10
gamma: 0.99
gae_lambda: 0.95
ent_coef: 0.01
total_timesteps: 1000000
